{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbfb80f0",
   "metadata": {},
   "source": [
    "### Large Language Models\n",
    "\n",
    "Generative AI models such as GPT-4 and other similar models use decoder-only transformer model architecture. They are trained on a large corpus and are rumored to have trillions of parameters. Many of these models are closed sourced but have been made available via APIs.\n",
    "\n",
    "[HuggingFace](https://huggingface.co/models) is a great place to find open source models. You can use models hosted on their platforms using their [huggingface python library](https://huggingface.co/docs/huggingface_hub/index).\n",
    "\n",
    "[Gradio](https://www.gradio.app/guides/quickstart) is a great place to host your demo machine learning projects/apps for free.\n",
    "\n",
    "\n",
    "#### Prompt engineering\n",
    "Prompt engineering can be especially useful while using LLMs for building apps. For example, Open AI (the company that released GPT models) has shared some [strategies and tactics](https://platform.openai.com/docs/guides/prompt-engineering) to make the most out of their LLM models.\n",
    "\n",
    "Some tricks recommended by OpenAI are as follows:\n",
    "\n",
    "* Be more specific E.g., if you want the output to be a comma separated list, ask it to return a comma separated list. If you want it to say \"I don't know\" when it doesn't know the answer, tell it 'Say \"I don't know\" if you do not know the answer.' The more specific your instructions, the better the model can respond.\n",
    "* Provide Context: Help the model understand the bigger picture of your request. This could be background information, examples/demonstrations of what you want or explaining the purpose of your task.\n",
    "* Ask the model to answer as if it was an expert. Explicitly asking the model to produce high quality output or output as if it was written by an expert can induce the model to give higher quality answers that it thinks an expert would write. Phrases like \"Explain in detail\" or \"Describe step-by-step\" can be effective.\n",
    "* Prompt the model to write down the series of steps explaining its reasoning. If understanding the 'why' behind an answer is important, prompt the model to include its reasoning. This can be done by simply adding a line like \"Let's think step by step\" before each answer.\n",
    "\n",
    "\n",
    "#### Integrating external data to LLM models\n",
    "LLM models cannot reliably talk on topics that they are not trained on, but there are two techniques that can be used to integrate data not previously known to LLMs:\n",
    "* Fine-Tuning the models: This technique involves updating the weights/parameters of the LLM model using your own training corpus.\n",
    "* RAG (Retrieval-Augmented Generation)\n",
    "![](https://pvml.com/wp-content/uploads/2024/04/rag.png)\n",
    "\n",
    "We will learn more about both via our exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa4ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
